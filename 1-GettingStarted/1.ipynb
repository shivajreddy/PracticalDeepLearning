{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is it a cat model.  \n",
    "Here inputs are images.  \n",
    "Model is the Neural Net.  \n",
    "Weights are the weights in the Neural net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastbook\n",
    "fastbook.setup_book()\n",
    "from fastbook import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "path = untar_data(URLs.PETS)/'images'\n",
    "\n",
    "def is_cat(image):\n",
    "    return image[0].isupper()\n",
    "dls = ImageDataLoaders.from_name_func(\n",
    "    path, get_image_files(path), valid_pct=0.2, seed=42,\n",
    "    label_func=is_cat, item_tfms=Resize(224)\n",
    ")\n",
    "\n",
    "learn = vision_learner(dls, resnet34, metrics=error_rate)\n",
    "# learn.fine_tune(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network  \n",
    "\n",
    "Neural network, mathematically is a function, which is extremely flexible depending on its weights. The mathematical proof called **`Universal approximation theorem`** shows that this function can solve any problem to any level of accuracy in *theory*.  \n",
    "\n",
    "**`Stochastic Gradient Descent`**: Finding a new 'mechanism' for automatically updating weights for every problem.  \n",
    "\n",
    "Neural Network is a machine learning model. Neural Networks are highly flexible, and can be applied to a wide range of problems by finding the right weights.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning Jargon\n",
    "\n",
    "- The functional form of the *model* is called its *architecture* (but be carefulâ€”sometimes people use *model* as a synonym of *architecture*, so this can get confusing).\n",
    "- The *weights* are called *parameters*.\n",
    "- The *predictions* are calculated from the *independent variable*, which is the *data* not including the *labels*.\n",
    "- The *results* of the model are called *predictions*.\n",
    "- The measure of *performance* is called the *loss*.\n",
    "- The loss depends not only on the predictions, but also the correct *labels* (also known as *targets* or the *dependent variable*); e.g., \"dog\" or \"cat.\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/photo1.png\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weights are the parameters we tweak.\n",
    "Loss is the percentage that our model outputs(for validation,) when compared its results to the original results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "_PracticalDeepLearningVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
